{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORM Integration\n",
    "This notebook will look into integrating the Turing SDK by implementing the `ShortAnswerQuestion` object into an ORM model. For the purpose of simplicity, we will use the Django ORM in this notebook. However, as you will see, this integration works regardless of your ORM choice.\n",
    "\n",
    "To grade questions with Turing, you need to implement the two stages of the question grading lifecycle:\n",
    "1. Question object creation\n",
    "2. Question grading request\n",
    "\n",
    "Every request for question grading must address these two steps in one way or another. First, let's worry about creating a question object. As the name of this notebook suggests, we are going to create questions via an ORM model. To do this, we can implement an method on the ORM model, which utitlizes the fields of the model to create a `ShortAnswerQuestion` object.\n",
    "\n",
    "First let's set the stage with an ORM model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an ORM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db import models\n",
    "\n",
    "class QuizQuestion(models.Model):\n",
    "    FACTUAL = \"FA\"\n",
    "    OPTION = \"OP\"\n",
    "    ANALYSIS = \"AN\"\n",
    "    QUESTION_TYPE_CHOICES = [\n",
    "        (FACTUAL, \"Factual\"),\n",
    "        (OPINION, \"Opinion\"),\n",
    "        (ANALYSIS, \"Analysis\")\n",
    "    ]\n",
    "\n",
    "    _id = models.UUIDField(primary_key=True)\n",
    "    question = models.CharField(max_length=100)\n",
    "    example_answer = models.CharField(max_length=250)\n",
    "    question_type = models.CharField(max_length=2, choices =QUESTION_TYPE_CHOICES, default='FACTUAL')\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can find a fairly simple Django model for a Quiz Question. It defines a few basic fields for the database table and a standard `__str__` method, per the reccomendations of Django's docs. \n",
    "\n",
    "Now that we have our basic model setup, we can extend the model to easily create turing `ShortAnswerQuestion` objects directly through the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `ShortAnswerQuestion` Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db import models\n",
    "\n",
    "from turing.question import ShortAnswerQuestion, RubricType\n",
    "\n",
    "class QuizQuestion(models.Model):\n",
    "    FACTUAL = \"FA\"\n",
    "    OPTION = \"OP\"\n",
    "    ANALYSIS = \"AN\"\n",
    "    QUESTION_TYPE_CHOICES = [\n",
    "        (FACTUAL, \"Factual\"),\n",
    "        (OPINION, \"Opinion\"),\n",
    "        (ANALYSIS, \"Analysis\")\n",
    "    ]\n",
    "\n",
    "    _id = models.UUIDField(primary_key=True)\n",
    "    question = models.CharField(max_length=100)\n",
    "    example_answer = models.CharField(max_length=250)\n",
    "    question_type = models.CharField(max_length=2, choices =QUESTION_TYPE_CHOICES, default='FACTUAL')\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.question\n",
    "\n",
    "    @property\n",
    "    def rubric_type(self):\n",
    "        \"\"\"Converts the question_type field to a RubricType object.\"\"\"\n",
    "        match self.question_type:\n",
    "            case self.FACTUAL:\n",
    "                return RubricType.FACTUAL\n",
    "            case self.OPINION:\n",
    "                return RubricType.COMMUNICATION_RUBRIC\n",
    "            case self.ANALYSIS:\n",
    "                return RubricType.ANALYTICAL_RUBRIC\n",
    "            case _:\n",
    "                return RubricType.CUSTOM_RUBRIC\n",
    "\n",
    "    @property\n",
    "    def turing_question(self):\n",
    "        \"\"\"Converts the QuizQuestion to a Turing ShortAnswerQuestion\"\"\"\n",
    "        return ShortAnswerQuestion.from_rubric_type(\n",
    "            question=self.question,\n",
    "            example_answer=self.example_answer,\n",
    "            rubric_type=self.rubric_type\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By implementing two simple properties into our ORM model, we were able to convert our standard Django model into a `ShortAnswerQuestion` factory. Now, we can simply use these properties to create and grade `ShortAnswerQuestion` objects anywhere in our app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading a Question\n",
    "To keep with the Django theme, let's imagine we are in a view function now. We will call this the question grading view. In this view, we will query for a question through the `QuizQuestion` model, then use our properites and the provided `grade` method of the `ShortAnswerQuestion` object to grade the student's response with Turing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.http import HttpRequest, HttpResponse\n",
    "from django.views.decorators.http import require_http_methods\n",
    "\n",
    "@require_http_methods([\"POST\"])\n",
    "def grade_question_view(request: HttpRequest, question_id: str) -> HttpResponse:\n",
    "    \"\"\"Grades a student's response to a question.\"\"\"\n",
    "\n",
    "    # Get the question from the database\n",
    "    question = QuizQuestion.objects.get(_id=question_id)\n",
    "\n",
    "    # Use the custom property to get the turing question from the \n",
    "    # question model\n",
    "    turing_question = question.turing_question\n",
    "\n",
    "    # Get the student's answer from the request body\n",
    "    answer = request.POST.get(\"answer\")\n",
    "\n",
    "    # Grade the question with turing\n",
    "    feedback, score = turing_question.grade(answer)\n",
    "\n",
    "    # Return the results to the client\n",
    "    return HttpResponse({'feedback': feedback, 'score': score})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like that, we have extended our question model and implemented a view to access Turing's API. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
