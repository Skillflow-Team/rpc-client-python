{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Questions are the corner stone of the Turing SDK. The whole library revolves around defining and operating on question objects. In this notebook we will cover:\n",
    "1. Building a conceptual understanding of the `ShortAnswerQuestion` object\n",
    "2. Covering the different methods for defining questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Understanding of the `ShortAnswerQuestion` object\n",
    "If you haven't already, please read the `01_rubrics.ipynb` notebook, to gain a comprehensive understanding of the Rubric object. That knowledge will be critical in understanding questions.\n",
    "\n",
    "The question object is the centeral focus of Turing's SDK. The main goal of the library is to provide a clean interface for creating and defining question objects and then seamlessly grading responses to those questions. Before diving into specifics, it is important to understand the pieces of a question. The question object has three attributes:\n",
    "- `body` (`str`): The body of the question\n",
    "- `example_answer` (`str`): The example answer to the question\n",
    "- `rubric` (`Rubric`): The grading rubic used by the LLM for grading the question\n",
    "\n",
    "Please see the `01_rubrics.ipynb` for details on defining Rubrics. As you can see, most of the difficulty with implementing questions actually lies in implementing the Rubric itself. Once that is handled, the rest of the question model is pretty straightforward. The `ShortAnswerQuestion` defines a central method, `grade(self, answer: str) -> Tuple[str, float]:` which can be used for grading questions. Every implementation of a Short Answer Question should be motivated with the end goal of calling the `grade` method.\n",
    "\n",
    "To get to that point, we first need to be able to define questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Methods for Defining Questions\n",
    "\n",
    "The `body` and `example_answer` attributes are simple to define, but definining the `Rubric` can take some more work. After selecting how you want your Rubric to be defined, you then need to choose how that implementation will be integrated with your implementation of the `ShortAnswerQuestion` class. \n",
    "\n",
    "We can define a `ShortAnswerQuestion` object in one of three ways. \n",
    "1. Without a Rubric (then adding one after instantiation)\n",
    "2. Directly from a `RubricType` (wrapper for the `Rubric.from_rubric_type` class method)\n",
    "3. Directly from a data payload (using a dictonary to define the question attributes)\n",
    "\n",
    "Let's look at each of these examples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without a Rubric\n",
    "\n",
    "You can create a `ShortAnswerQuestion` without a rubric. In this case, the rubric attribute will be an empty `Rubric` object. We can then use the `add_critiera` method or the `set_rubric` method to define the question's rubric after instantiation. The `add_criteria` method is a wrapper to the `add_criteria` method on the rubric object. Below, we see how these two methods of setting the rubric after instantiation can both be achieved by either adding criteria to the rubric or adding criteria to the question directly.\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turing import ShortAnswerQuestion, Rubric, Objective\n",
    "\n",
    "# EXAMPLE 1: Defining the question wihtout a rubric, and adding the criteria through the question obect\n",
    "question = ShortAnswerQuestion(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris\",\n",
    ")\n",
    "\n",
    "print(question.rubric.rubric_type) # RubricType.CUSTOM\n",
    "print(question.rubric.size) # 0 (the size of the default empty rubric)\n",
    "\n",
    "# Adding the criteria directly to the question\n",
    "question.add_criteria(Objective.FACTUAL, 1.5)\n",
    "question.add_criteria(Objective.ANALYSIS, 1.0)\n",
    "question.add_criteria(Objective.CLARITY, 0.5)\n",
    "\n",
    "print(question.rubric.rubric_type) # RubricType.CUSTOM\n",
    "print(question.rubric.size) # 3\n",
    "\n",
    "\n",
    "# EXAMPLE 2: If you perfer to build the rubric seperately, using the `Rubric` API, you may do so, then add the completed rubric to the question\n",
    "question = ShortAnswerQuestion(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris\",\n",
    ")\n",
    "\n",
    "rubric = Rubric.empty()\n",
    "rubric.add_criteria(Objective.FACTUAL, 1.5)\n",
    "rubric.add_criteria(Objective.ANALYSIS, 1.0)\n",
    "rubric.add_criteria(Objective.CLARITY, 0.5)\n",
    "\n",
    "question.set_rubric(rubric)\n",
    "\n",
    "print(question.rubric.rubric_type) # RubricType.CUSTOM\n",
    "print(question.rubric.size) # 3\n",
    "\n",
    "# EXAMPLE 3: We can also built the rubric prior to instantiating the question, and then pass the rubric directly to the question as a kwarg\n",
    "rubric = Rubric.empty()\n",
    "rubric.add_criteria(Objective.FACTUAL, 1.5)\n",
    "rubric.add_criteria(Objective.ANALYSIS, 1.0)\n",
    "rubric.add_criteria(Objective.CLARITY, 0.5)\n",
    "\n",
    "# Instantiate the question with the rubric object directly\n",
    "question = ShortAnswerQuestion(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris\",\n",
    "    rubric=rubric\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this example demonstrates, we have plenty of ways to define custom rubrics and set them in our question object using the Turing SDK. These above methods will provide the simplest implementation in terms of additional code needed, as they leverage the built in APIs of the Rubric and Question models to simplify the process.\n",
    "\n",
    "\n",
    "### Directly from a `RubricType` object\n",
    "\n",
    "You can also create a `ShortAnswerQuestion` directly from a `RubricType`. The `RubricType` enum class predefines sets of `GradingCriteria` for different use cases. This method of rubric definition is the same as using the `Rubric.from_rubric_type` implementation.\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turing import ShortAnswerQuestion, RubricType\n",
    "\n",
    "# Example 1: We can define the question and the rubric type, and the rubric will be automatically generated\n",
    "question = Question.from_rubric_type(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris\",\n",
    "    rubric_type=RubricType.FACTUAL\n",
    ")\n",
    "\n",
    "print(question.rubric.rubric_type) # RubricType.FACTUAL\n",
    "print(question.rubric.size) # 3\n",
    "\n",
    "\n",
    "# Example 2: This is the same as using the Rubric API to define the rubric, then passing it to the question\n",
    "rubric = Rubric.from_rubric_type(RubricType.FACTUAL)\n",
    "question = ShortAnswerQuestion(\n",
    "    question=\"What is the capital of France?\",\n",
    "    answer=\"Paris\",\n",
    "    rubric=rubric\n",
    ")\n",
    "\n",
    "print(question.rubric.rubric_type) # RubricType.FACTUAL\n",
    "print(question.rubric.size) # 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these examples show, we can simply leverage the Rubric's `from_rubric_type` method, through the question object. This creates for less boilerplate code, and a simple, one-line definition for question objects.\n",
    "\n",
    "### Directly from a Data Payload\n",
    "\n",
    "Finally, you can create a `ShortAnswerQuestion` directly from a data payload. This involves deserializing a Python object and building the `GradingCriteria` objects directly from the payload. To do this, we will have to override the `from_dict` classmethod. Note, that the `from_dict` method calls the `from_dict` method on the Rubric class under the hood. We can choose to leverage this functionality on the Rubric class.\n",
    "\n",
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turing import ShortAnswerQuestion, Rubric, RubricType\n",
    "\n",
    "# Custom datapaylod that isnot intrinsically supported by the Turing API\n",
    "payload = {\n",
    "    \"question\": {\n",
    "        'body': \"What is the capital of France?\",\n",
    "        'example_answer': 'Paris',\n",
    "    }\n",
    "    'tags': ['geography', 'factual']\n",
    "}\n",
    "\n",
    "class CustomQuestion(ShortAnswerQuestion):\n",
    "    \"\"\"Custom question object for the Turing API\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def resolve_rubric_from_tags(tags: List[str]) -> Rubric:\n",
    "        \"\"\"Custom method for creating the Rubric based on the question tags.\"\"\"\n",
    "        if 'factual' in tags:\n",
    "            return Rubric.from_rubric_type(RubricType.FACTUAL_RUBRIC)\n",
    "        if 'analysis' in tags:\n",
    "            return Rubric.from_rubric_type(RubricType.ANALYTICAL)\n",
    "        if 'reaserch' in tags:\n",
    "            return Rubric.from_rubric_type(RubricType.COMPREHENSIVE_RUBRIC)\n",
    "        else:\n",
    "            return Rubric.from_rubric_type(RubricType.COMMUNICATION_RUBRIC)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Union[str, List[str]]]) -> 'CustomQuestion':\n",
    "        \"\"\"Override the default `from_dict` method to provide custom parsing logic.\"\"\"\n",
    "        # Extract the low-level attributes from the payload\n",
    "        body = data['question']['body']\n",
    "        answer = data['question']['example_answer']\n",
    "\n",
    "        # Extract the tags to be used for the rubric\n",
    "        tags = data['tags']\n",
    "        rubric = cls.resolve_rubric_from_tags(tags)\n",
    "        return cls(\n",
    "            body=body,\n",
    "            example_answer=answer,\n",
    "            rubric=rubric\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can further extend these methods to provide a more intricate algorithm for determing RubricTypes. Moreover, we can also use this method to implement custom logic for building custom rubrics from the payload. More on this example can be seen in the `01_rubrics.ipynb` notebook, in the section about defining rubrics from custom payloads.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As you can see, the question object provides a clean and simple API for creating and grading questions. It seeks to implement itself with the Rubric in such a way that allows developers to ignore or further leverage the Rubric API, based on their specific use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
